{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "o2Lf6OxJ3RCJ",
        "9_SzuaHxDCsZ",
        "Wh4MBmczqwCT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HkHpdCmS31Eu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from datetime import *\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gu = ['강남구', '강동구', '광진구', '송파구', '성동구', '용산구', '마포구', '서초구', '동작구', '영등포구', '강서구']\n",
        "name_abb = ['GN', 'GD', 'GJ', 'SP', 'SD', 'YS', 'MP', 'SCH', 'DJ', 'YDP', 'GS']"
      ],
      "metadata": {
        "id": "dcGRbmYA39uO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 분기별 연도별 11개구 구분"
      ],
      "metadata": {
        "id": "o2Lf6OxJ3RCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분기별로 나눠져 있으면 이걸로\n",
        "unpre_dust = pd.read_csv('DATA\\에어코리아 최종측정 대기질 데이터/2016/2016년 4분기.csv', encoding='cp949')\n",
        "## csv 파일 저장시 clean01 / 2016_()분기/2016_()_{} 로 이름 바꾸기\n",
        "for i in range(len(Gu)):\n",
        "    Gu_name = Gu[i]\n",
        "    Gu_abb = name_abb[i]\n",
        "    print(Gu_name, Gu_abb)\n",
        "    unpre_Gu = unpre_dust[unpre_dust['측정소명'].str.contains(Gu_name)]\n",
        "    unpre_Gu.to_csv('./DATA/clean01/2016_4분기/2016_4분기_{}.csv'.format(Gu_abb), index=False)\n",
        "    print(unpre_Gu)"
      ],
      "metadata": {
        "id": "kL-0Zqon39zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 월별로 나눠져 있으면 이걸로\n",
        "unpre_dust = pd.read_excel('./DATA/에어코리아 최종측정 대기질 데이터/2020/2020년 1월.xlsx')\n",
        "\n",
        "for i in range(len(Gu)):\n",
        "    Gu_name = Gu[i]\n",
        "    Gu_abb = name_abb[i]\n",
        "    print(Gu_name, Gu_abb)\n",
        "    unpre_Gu = unpre_dust[unpre_dust['측정소명'].str.contains(Gu_name)]\n",
        "    unpre_Gu.to_csv('./DATA/clean01/2020_4분기/2020_4분기_12월/2020_12월_{}.csv'.format(Gu_abb), index=False)\n",
        "    print(unpre_Gu)"
      ],
      "metadata": {
        "id": "57gzLQDg394-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 연도별로 concat(axis = 0 => 행기준, 동일 column을 기준으로 위아래로 합쳐짐 / axis = 1 => 열기준, 옆으로 붙여짐)\n",
        "\n",
        "# df1 = pd.read_csv('./DATA/clean01/2018_1분기/2018_1분기_YS.csv')\n",
        "# df2 = pd.read_csv('./DATA/clean01/2018_2분기/2018_2분기_YS.csv')\n",
        "# df3 = pd.read_csv('./DATA/clean01/2018_3분기/2018_3분기_YS.csv')\n",
        "# df4 = pd.read_csv('./DATA/clean01/2018_4분기/2018_4분기_YS.csv')\n",
        "\n",
        "\n",
        "# total_YS_2018 = pd.concat([df1, df2, df3, df4], axis = 0)\n",
        "# print(total_YS_2018)\n",
        "\n",
        "# total_YS_2018.to_csv('./DATA/Concat_By_Year/2018/2018년_용산구.csv', index= False)\n"
      ],
      "metadata": {
        "id": "f1qvatwo4PnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 월별로 있는 CONCAT\n",
        "\n",
        "# df1 = pd.read_csv('./DATA/clean01/2020_1분기/2020_1분기_1월/2020_1월_YS.csv')\n",
        "# df2 = pd.read_csv('./DATA/clean01/2020_1분기/2020_1분기_2월/2020_2월_YS.csv')\n",
        "# df3 = pd.read_csv('./DATA/clean01/2020_1분기/2020_1분기_3월/2020_3월_YS.csv')\n",
        "# df4 = pd.read_csv('./DATA/clean01/2020_2분기/2020_2분기_4월/2020_4월_YS.csv')\n",
        "# df5 = pd.read_csv('./DATA/clean01/2020_2분기/2020_2분기_5월/2020_5월_YS.csv')\n",
        "# df6 = pd.read_csv('./DATA/clean01/2020_2분기/2020_2분기_6월/2020_6월_YS.csv')\n",
        "# df7 = pd.read_csv('./DATA/clean01/2020_3분기/2020_3분기_7월/2020_7월_YS.csv')\n",
        "# df8 = pd.read_csv('./DATA/clean01/2020_3분기/2020_3분기_8월/2020_8월_YS.csv')\n",
        "# df9 = pd.read_csv('./DATA/clean01/2020_3분기/2020_3분기_9월/2020_9월_YS.csv')\n",
        "# df10 = pd.read_csv('./DATA/clean01/2020_4분기/2020_4분기_10월/2020_10월_YS.csv')\n",
        "# df11 = pd.read_csv('./DATA/clean01/2020_4분기/2020_4분기_11월/2020_11월_YS.csv')\n",
        "# df12 = pd.read_csv('./DATA/clean01/2020_4분기/2020_4분기_12월/2020_12월_YS.csv')\n",
        "\n",
        "# total_YS_2020 = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12], axis = 0)\n",
        "# print(total_YS_2020)"
      ],
      "metadata": {
        "id": "COJq17474Ppj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3시간 평균"
      ],
      "metadata": {
        "id": "9_SzuaHxDCsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data/project02_dust/서울시_열린데이터광장/연도별_구별구분/2016/2016_DJ_data.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "_CWn-Koos-1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리(3시간 이동평균)\n",
        "for i in range(len(Gu)):\n",
        "    unpre_Gu = pd.read_csv('/content/drive/MyDrive/data/project02_dust/서울시_열린데이터광장/연도별_구별구분/2019/2019_{}_data.csv'.format(name_abb[i]))\n",
        "    print(Gu[i])\n",
        "\n",
        "    while unpre_Gu['미세먼지(PM10)'].isna().sum() and unpre_Gu['초미세먼지(PM25)'].isna().sum() != 0:\n",
        "        unpre_Gu[['미세먼지(PM10)', '초미세먼지(PM25)']] = unpre_Gu[['미세먼지(PM10)', '초미세먼지(PM25)']].fillna(unpre_Gu[['미세먼지(PM10)', '초미세먼지(PM25)']].rolling(window = 3, min_periods=1).mean())\n",
        "        if unpre_Gu['미세먼지(PM10)'].isna().sum() and unpre_Gu['초미세먼지(PM25)'].isna().sum() != 0:\n",
        "            unpre_Gu[['미세먼지(PM10)', '초미세먼지(PM25)']] = unpre_Gu[['미세먼지(PM10)', '초미세먼지(PM25)']].fillna(0)\n",
        "\n",
        "    unpre_Gu.to_csv('/content/drive/MyDrive/data/project02_dust/서울시_열린데이터광장/3h_mean_done/2019/2019_{}_3h'.format(name_abb[i]), index=False)"
      ],
      "metadata": {
        "id": "SS0MP4j54Wn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(Gu)):\n",
        "    d = pd.read_csv('/content/drive/MyDrive/data/project02_dust/서울시_열린데이터광장/3h_mean_done/2019/2019_{}_3h'.format(name_abb[i]))\n",
        "    print(Gu[i],\"는\")\n",
        "    print(d.isna().sum())\n",
        "    print(d[d['미세먼지(PM10)'] == 0])\n",
        "    print('ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ')\n"
      ],
      "metadata": {
        "id": "K0ar1lqrsBYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기상청 + 서울시 데이터 merge"
      ],
      "metadata": {
        "id": "Wh4MBmczqwCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gi = pd.read_csv('/content/drive/MyDrive/data/project02_dust/기상청 추가 자료/8방위, 강수량 이후/기상청2019_최종.csv', index_col = 0)\n",
        "gi.drop(['지점'], inplace=True, axis = 1)\n",
        "gi.drop(['지점명'], inplace=True, axis = 1)\n",
        "gi['일시'] = pd.to_datetime(gi['일시'])"
      ],
      "metadata": {
        "id": "9Ne_H2eNqMSD"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16년도 17년도 컬럼명 변경 및 컬럼 순서 정렬\n",
        "gi.rename(columns = {'풍향범주(corr)' : '풍향범주_corr'}, inplace = True)\n",
        "gi = gi[['일시', '기온(°C)', '강수량(mm)', '풍향(16방위)', '풍향범주_corr', '풍향범주']]"
      ],
      "metadata": {
        "id": "B0AelecKfLoW"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gi.isna().sum()"
      ],
      "metadata": {
        "id": "-JuCuNXooxWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(name_abb)):\n",
        "    print('이번 차례는', name_abb[i], '입니다.')\n",
        "    df = pd.read_csv('/content/drive/MyDrive/data/project02_dust/서울시_열린데이터광장/3h_mean_done/2019/2019_{}_3h'.format(name_abb[i]))\n",
        "    df['일시'] = pd.to_datetime(df['일시'])\n",
        "    a = pd.merge(df, gi,\n",
        "                 left_on = '일시',right_on = '일시',\n",
        "                 how = 'left')\n",
        "    if a.isna().sum().sum() != 0:\n",
        "        a = a.fillna(method = 'ffill') ##################################### 재설정!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    else:\n",
        "        pass\n",
        "    print('해당 df의 Nan값의 합은', a.isna().sum(), '입니다.')\n",
        "    print('ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ')\n",
        "    a.to_csv('/content/drive/MyDrive/data/project02_dust/최종 데이터/2019/2019_semi_final_{}_data.csv'.format(name_abb[i]))"
      ],
      "metadata": {
        "id": "vy5L8nbAt2Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 지역별 16 ~ 19년도 합치기"
      ],
      "metadata": {
        "id": "8BYgy32x3Y_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(name_abb)):\n",
        "    df1 = pd.read_csv('/content/drive/MyDrive/data/project02_dust/최종 데이터/2016/2016_semi_final_{}_data.csv'.format(name_abb[i]), index_col = 0)\n",
        "    df2 = pd.read_csv('/content/drive/MyDrive/data/project02_dust/최종 데이터/2017/2017_semi_final_{}_data.csv'.format(name_abb[i]), index_col = 0)\n",
        "    df3 = pd.read_csv('/content/drive/MyDrive/data/project02_dust/최종 데이터/2018/2018_semi_final_{}_data.csv'.format(name_abb[i]), index_col = 0)\n",
        "    df4 = pd.read_csv('/content/drive/MyDrive/data/project02_dust/최종 데이터/2019/2019_semi_final_{}_data.csv'.format(name_abb[i]), index_col = 0)\n",
        "\n",
        "\n",
        "    total = total = pd.concat([df1, df2, df3, df4], axis = 0)\n",
        "    total = total.sort_values(by = '일시').reset_index(drop = True)\n",
        "    a = total.isna().sum()\n",
        "    b = name_abb[i]\n",
        "    print(f\"{b}의 fillna 값은 {a} 입니다.\")\n",
        "    total.to_csv('/content/drive/MyDrive/data/project02_dust/최종 데이터/기상청_서울시_구별_연도별_concat_후/total_{}.csv'.format(name_abb[i]))\n"
      ],
      "metadata": {
        "id": "QbAWLMVJvuRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Nan 값 확인\n",
        "for i in range(len(name_abb)):\n",
        "    want = pd.read_csv('/content/drive/MyDrive/data/project02_dust/최종 데이터/기상청_서울시_구별_연도별_concat_후/total_{}.csv'.format(name_abb[i]), index_col=0)\n",
        "    print(\"ㅡㅡㅡ 구분선 ㅡㅡㅡ\")\n",
        "    print(Gu[i] + \"의 결과는 아래와 같습니다. \")\n",
        "    print(want.isnull().sum())"
      ],
      "metadata": {
        "id": "g5LMKIGcIg9g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}